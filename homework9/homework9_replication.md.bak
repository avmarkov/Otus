# Домашняя работа № 9. Репликация.

### 1. На 1 ВМ создаем таблицы test для записи, test2 для запросов на чтение.
> Я создал виртуальную машину с Ubuntu 22.04.1 LTS в Яндексе. Назвал ее ubuntu2204-vm. Скрин виртуальной машине Яндекса на картинке ниже:
> <image src="images/vm.png" alt="vm">

> Вместо трех ВМ я создал три кластера PostgreSQL:
> 
> <image src="images/3_pg_clusters.png" alt="3_pg_clusters">


### 2.  Создаем публикацию таблицы test и подписываемся на публикацию таблицы test2 с ВМ №2.

### 3.  На 2 ВМ создаем таблицы test2 для записи, test для запросов на чтение. 

### 4. Создаем публикацию таблицы test2 и подписываемся на публикацию таблицы test1 с ВМ №1. 

### 5.  3 ВМ использовать как реплику для чтения и бэкапов (подписаться на таблицы из ВМ №1 и №2 ). 

### 6.  Небольшое описание, того, что получилось.



### 2. Поставить на неё PostgreSQL 14 любым способом
> Т.к. версия Ubuntu 22.04, устанавливаю PostgreSQL так (знаю, что установится 14-я версия):
> ```sh
> aleksandr@ubuntu2204-vm:~$ sudo apt-get -y install postgresql
> ```
> Кластер создался:
> 
> <image src="images/pg_cluster.png" alt="pg_cluster">

### 3. Настроить кластер PostgreSQL 14 на максимальную производительность не обращая внимание на возможные проблемы с надежностью в случае аварийной перезагрузки виртуальной машины
> У меня ВМ с 2 ядрами, 4 GB RAM, поэтому параметры выбрал такими:
> ```sh
> max_connections = 100
> shared_buffers = 1GB
> effective_cache_size = 3GB
> maintenance_work_mem = 256MB
> checkpoint_completion_target = 0.9
> wal_buffers = 16MB
> default_statistics_target = 100
> random_page_cost = 4
> effective_io_concurrency = 2
> work_mem = 2621kB
> min_wal_size = 1GB
> max_wal_size = 4GB
> ```
> Отдельно обращаю внимание, что пока оставил "synchronous_commit = on"

### 3. Нагрузить кластер через утилиту https://github.com/Percona-Lab/sysbench-tpcc (требует установки https://github.com/akopytov/sysbench) или через утилиту pgbench (https://postgrespro.ru/docs/postgrespro/14/pgbench)
> Нагружаю кластер через pgbench
> ```sh
> aleksandr@ubuntu2204-vm:~$ sudo -u postgres pgbench -i postgres
> ```

> Нагружаю кластер так (120 сек длительность теста, каждые 10 сек вывожу на экран информацию о tps, 50 подключений)
> ```sh
> aleksandr@ubuntu2204-vm:~$ sudo -u postgres pgbench -c 50 -P 10 -T 120 -U postgres postgres
> ```

> Результат
> 
> <image src="images/tps1.png" alt="tps1">

> Теперь, не обращая внимание на возможные проблемы с надежностью в случае аварийной перезагрузки виртуальной машины, устанавливаю параметр synchronous_commit = off
>
> Запускаю такой же тест:  
> ```sh
> aleksandr@ubuntu2204-vm:~$ sudo -u postgres pgbench -c 50 -P 10 -T 120 -U postgres postgres
> ```

> Результат
>
> <image src="images/tps2.png" alt="tps2">

### 4. Написать какого значения tps удалось достичь, показать какие параметры в какие значения устанавливали и почему
> tps с synchronous_commit = off оказался примерно в 5 раз больше (tps = 2148). Т.е. сервер работает быстрее в 5 раз. Но в этом случае сбой операционной системы или базы данных может привести к потере последних транзакций, считавшихся зафиксированными.
>
> Кроме этого установил:
> * shared_buffers = 1GB (25 % от общей RAM на сервере)
> * effective_cache_size = 3GB (75% от общей RAM на сервере)
> * maintenance_work_mem = 256MB (Определяет максимальное количество ОП для операций типа VACUUM, CREATE INDEX, CREATE FOREIGN KEY)
> * checkpoint_completion_target = 0.9 (Взял из PGTune. Задаёт целевое время для завершения процедуры контрольной точки, как коэффициент для общего времени между контрольными точками)
> * wal_buffers = 16MB (Объём разделяемой памяти, который будет использоваться для буферизации данных WAL, ещё не записанных на диск. По умолчанию -1, определяется автоматически, как 1/32 от **shared_buffers**, но не больше, чем 16 МБ (в ручную можно задавать большие значения). Обычно ставят 16 МБ)
> * default_statistics_target = 100 (Чем больше установленное значение, тем больше времени требуется для выполнения ANALYZE, но тем выше может быть качество оценок планировщика. Значение этого параметра по умолчанию — 100)
> * random_page_cost = 4 (Задаёт приблизительную стоимость чтения одной произвольной страницы с диска. Значение по умолчанию равно 4.0.)
> * effective_io_concurrency = 2 (Допустимое число одновременных операций ввода/вывода. У меня HDD, в этом случае рекомендуют ставить 2)
> * work_mem = 2621kB (Взял их PGTune. Обычно рассчитывается так: Total RAM * 0.25 / max_connections)
> * min_wal_size = 1GB (ограничивает снизу число файлов WAL, которые будут переработаны для будущего использования)
> * max_wal_size = 4GB (Максимальный размер, до которого может вырастать WAL между автоматическими контрольными точками в WAL. Значение по умолчанию — 1 ГБ. Увеличение этого параметра может привести к увеличению времени, которое потребуется для восстановления после сбоя, но позволяет реже выполнять операцию сбрасывания на диск.)